{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this notebook we will follow the framework laid out by openai to finetune: [link](https://platform.openai.com/docs/guides/fine-tuning/introduction)\n",
    "\n",
    "we will syntheitcally create our dataset using an LLM by boostrapping a few samples. we will then evaulate the validity of this dataset using an LLM.\n",
    "\n",
    "will repurpose the Q&A on Retrieved Data in Arize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from jinja2 import Template\n",
    "from sklearn.metrics import classification_report\n",
    "from pycm import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openai import OpenAI\n",
    "import phoenix.evals.default_templates as templates\n",
    "from phoenix.evals import (\n",
    "    OpenAIModel,\n",
    "    llm_classify,\n",
    ")\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets try to predict normally with 3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_normal = '''I recently purchased the Galaxy Explorer drone and am absolutely thrilled with its performance. The drone's battery life is impressive, allowing for extended flight times, and the camera quality is outstanding, capturing crisp and clear images from great heights. The intuitive controls made it easy for me as a beginner to navigate, and I've been able to capture some truly breathtaking footage. Highly recommend to anyone looking for a reliable and high-quality drone.'''\n",
    "negative_normal = '''Had dinner at The Green Terrace last night and was deeply disappointed. Despite the cozy ambiance, the service was sluggish, and our orders took forever to arrive. When the food finally came, it was lukewarm at best. The pasta was overcooked, and the salad lacked freshness. It's a shame because I had high expectations based on the reviews. Sadly, I won't be returning or recommending this place to friends.'''\n",
    "positive_tough = '''Lost my job, but at least I won't have to endure that dreadful commute anymore'''\n",
    "negative_tough = '''Your presentation was surprisingly good; I expected much less'''\n",
    "\n",
    "SYSTEM_PROMPT = '''You are given a social media review. Classify it as postive, negative. '''\n",
    "\n",
    "original_dataset = [[positive_normal, 'positive'],\n",
    "               [negative_normal, 'negative'], \n",
    "               [positive_tough, 'positive'],\n",
    "               [negative_tough, 'negative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(social_media_post, model=\"gpt-3.5-turbo\"):\n",
    "    response = client.chat.completions.create(model=model, \n",
    "                                              temperature = 0.1,\n",
    "                                              messages=[{\"role\": \"system\", \"content\": SYSTEM_PROMPT}, \n",
    "                                                        {\"role\": \"user\", \"content\": social_media_post}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(original_dataset, columns=['text', 'label'])\n",
    "df['predicted_label'] = df['text'].apply(classify_sentiment).apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct'] = df['label'] == df['predicted_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_incorrect = df[~df['correct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy for base gpt-3.5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I recently purchased the Galaxy Explorer drone...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Had dinner at The Green Terrace last night and...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lost my job, but at least I won't have to endu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your presentation was surprisingly good; I exp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  I recently purchased the Galaxy Explorer drone...  positive   \n",
       "1  Had dinner at The Green Terrace last night and...  negative   \n",
       "2  Lost my job, but at least I won't have to endu...  positive   \n",
       "3  Your presentation was surprisingly good; I exp...  negative   \n",
       "\n",
       "  predicted_label  correct  \n",
       "0        positive     True  \n",
       "1        negative     True  \n",
       "2        positive     True  \n",
       "3        positive    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correct'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a dataset for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are responsible for creating a dataset of social media posts and their associated sentiments(postiive or negative).\n",
      "\n",
      "Read the instructions below carefully and follow each step in order to accurately generate your response.\n",
      "\n",
      "Please generate 20 sets of social media posts. Each set should not share similar context.\n",
      "\n",
      "Please output the sets in the following format:\n",
      "{'set-1': [<POST>, sentiment],\n",
      "    'set-2': [<POST>, sentiment], ...,\n",
      "    'set-20': [<POST>, sentiment]}\n",
      "\n",
      "Here are some examples:\n",
      "{'set-1': (\"I recently purchased the Galaxy Explorer drone and am absolutely thrilled with its performance. The drone's battery life is impressive, allowing for extended flight times, and the camera quality is outstanding, capturing crisp and clear images from great heights. The intuitive controls made it easy for me as a beginner to navigate, and I've been able to capture some truly breathtaking footage. Highly recommend to anyone looking for a reliable and high-quality drone.\", 'positive'),\n",
      "    'set-2': (\"Had dinner at The Green Terrace last night and was deeply disappointed. Despite the cozy ambiance, the service was sluggish, and our orders took forever to arrive. When the food finally came, it was lukewarm at best. The pasta was overcooked, and the salad lacked freshness. It's a shame because I had high expectations based on the reviews. Sadly, I won't be returning or recommending this place to friends.\", 'negative'),\n",
      "    'set-3': (\"Lost my job, but at least I won't have to endure that dreadful commute anymore\", 'positive'),\n",
      "    'set-4': (\"Your presentation was surprisingly good; I expected much less\", 'negative')}\n",
      "\n",
      "1. Please provide your response in a strictly valid RFC8259 JSON format.\n",
      "2. Your JSON response should exclude any characters or text that are not part of the JSON structure, such as the word 'json', annotations, markdown syntax, or clarifying text.\n",
      "3. Begin your response with a JSON opening curly brace and end with a closing curly brace. The response should consist solely of the JSON object.\n",
      "4. Ensure your JSON response does not include whitespaces.\n",
      "\n",
      "No whitespace RFC8259-compliant JSON response (do not truncate):\n"
     ]
    }
   ],
   "source": [
    "# Format the examples\n",
    "formatted_examples = \",\\n    \".join([f\"'set-{i+1}': (\\\"{text}\\\", '{sentiment}')\" for i, (text, sentiment) in enumerate(original_dataset)])\n",
    "formatted_examples = '{'+formatted_examples+'}'\n",
    "\n",
    "# Step 1: Read the file content\n",
    "with open('dataset_generator_template.txt', 'r') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# Step 3: Render the template with examples\n",
    "template = Template(file_content)\n",
    "dataset_gen_system_prompt = template.render(examples=formatted_examples)\n",
    "\n",
    "print(dataset_gen_system_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"set-1\":[\"Just tried the new caramel macchiato from JavaBeans Cafe, and it's a game changer! Perfectly balanced and not too sweet. #CoffeeLover\",\"positive\"],\"set-2\":[\"Can't believe I wasted two hours on 'The Endless Night'. Worst movie ever with a plot that makes zero sense and terrible acting.\",\"negative\"],\"set-3\":[\"Finally joined the gym and had my first workout today. Feeling motivated and ready to get in shape!\",\"positive\"],\"set-4\":[\"My phone's latest update has made it slower than ever. Really regretting this update.\",\"negative\"],\"set-5\":[\"The book club's selection this month was a real page-turner. Couldn't put it down until I finished it!\",\"positive\"],\"set-6\":[\"Tried the new sushi place downtown and was not impressed. The fish didn't taste fresh and the rolls were poorly made.\",\"negative\"],\"set-7\":[\"Landed my dream job today! So grateful for this opportunity and excited to start.\",\"positive\"],\"set-8\":[\"Our vacation was ruined by the constant rain. Didn't get to do half the things we planned.\",\"negative\"],\"set-9\":[\"This new meditation app has been a lifesaver. Feeling more centered and calm than I have in years.\",\"positive\"],\"set-10\":[\"The service at the post office is unbearable. Waited in line for an hour just to send a package.\",\"negative\"],\"set-11\":[\"Saw the most beautiful sunset while hiking today. Nature is truly amazing.\",\"positive\"],\"set-12\":[\"The air conditioner broke during the hottest week of the year. Absolutely miserable experience.\",\"negative\"],\"set-13\":[\"Passed my driving test on the first try! So happy and relieved.\",\"positive\"],\"set-14\":[\"The concert was a huge disappointment. The sound quality was terrible, and the band seemed uninterested.\",\"negative\"],\"set-15\":[\"Adopted a puppy and it's been the best decision. Brings so much joy and energy into our home.\",\"positive\"],\"set-16\":[\"My flight got canceled last minute, and the airline's customer service was no help at all.\",\"negative\"],\"set-17\":[\"Started learning Spanish on this new app and I'm already making progress. It makes learning so much fun!\",\"positive\"],\"set-18\":[\"The hotel we stayed at had bedbugs. Worst vacation experience ever.\",\"negative\"],\"set-19\":[\"Volunteered at the local food bank today. It feels good to give back to the community.\",\"positive\"],\"set-20\":[\"The graphics on this new video game are underwhelming. Definitely not worth the hype.\",\"negative\"]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_dataset():\n",
    "    dataset_response = client.chat.completions.create(model='gpt-4-turbo-preview', \n",
    "                                              temperature = 0.1,\n",
    "                                              messages=[{\"role\": \"system\", \"content\": dataset_gen_system_prompt}, \n",
    "                                                        {\"role\": \"user\", \"content\": \"JSON Response:\"}]).choices[0].message.content\n",
    "    # sometimes the string ```json``` is not present in the response, so we need to check for it\n",
    "    # if it is in there we want to remove it and the trailing ``` from the response\n",
    "    if 'json' in dataset_response:\n",
    "        parsed_response = dataset_response.replace('json', '')\n",
    "        parsed_response = parsed_response.replace('`', '')\n",
    "        parsed_response = json.loads(parsed_response)\n",
    "    else:\n",
    "        parsed_response = json.loads(dataset_response)\n",
    "    \n",
    "    return parsed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'set-1': [\"Just finished reading 'The Light in the Forest' and it was a journey full of emotions. The storytelling was captivating and the characters felt so real. Definitely a must-read for anyone who loves historical fiction.\", 'positive'], 'set-2': ['Tried the new vegan burger at Sunshine Caf√© and it was a letdown. The patty was dry and lacked flavor, and the bun was stale. Was really hoping for a better experience.', 'negative'], 'set-3': [\"Finally got to visit the Grand Canyon and it was absolutely breathtaking. Pictures don't do it justice. The vastness and beauty of it all is something everyone should experience.\", 'positive'], 'set-4': [\"My phone's latest update has made it slower than ever. Apps take forever to open and it keeps freezing. Really regretting this update.\", 'negative'], 'set-5': [\"The concert last night was incredible! The band's performance was electrifying and the crowd's energy was through the roof. Best live show I've been to in years.\", 'positive'], 'set-6': [\"Ordered a cake for my son's birthday from Sweet Treats Bakery and it was a disaster. The decoration was sloppy and it tasted like it was days old. Very disappointed.\", 'negative'], 'set-7': [\"Started using the new fitness app and I'm already seeing results. The workouts are challenging but doable, and the nutrition tips are really helpful. Feeling motivated!\", 'positive'], 'set-8': ['Our flight was delayed for 5 hours with no explanation from the airline. Missed our connecting flight and had to spend the night at the airport. Terrible experience.', 'negative'], 'set-9': [\"Adopted a puppy last week and it's been so much fun. He's brought so much joy and laughter into our home. Can't imagine life without him now.\", 'positive'], 'set-10': ['The hotel we stayed at had bedbugs. Came home covered in bites. It was a nightmare. Will never stay there again.', 'negative'], 'set-11': ['Passed my driving test on the first try! So excited to finally have my license. Freedom, here I come!', 'positive'], 'set-12': [\"The new sushi place in town is overrated. The sushi was mediocre and the prices were too high for the quality. Won't be going back.\", 'negative'], 'set-13': [\"Landed my dream job today! I'm over the moon and can't wait to start this new chapter in my life.\", 'positive'], 'set-14': ['My laptop crashed during an important presentation. Lost all my work and looked unprofessional. It was a complete disaster.', 'negative'], 'set-15': ['Went hiking in the mountains this weekend and the views were stunning. Nature is truly healing. Felt so refreshed after.', 'positive'], 'set-16': ['The customer service at this electronics store is non-existent. Asked for help multiple times and was completely ignored. Will be taking my business elsewhere.', 'negative'], 'set-17': [\"Joined a local book club and it's been such a rewarding experience. Meeting new people and discussing our thoughts on different books has been enlightening.\", 'positive'], 'set-18': [\"The city's new parking policy is a mess. It's now nearly impossible to find a spot downtown without paying exorbitant fees. Extremely frustrating.\", 'negative'], 'set-19': [\"Saw the northern lights for the first time and it was magical. An unforgettable experience that I'll cherish forever.\", 'positive'], 'set-20': [\"The public transport system is getting worse. Buses are always late and overcrowded. It's making my daily commute a nightmare.\", 'negative']}\n"
     ]
    }
   ],
   "source": [
    "parsed_response = generate_synthetic_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(parsed_response, orient='index', columns=['reference', 'output'])\n",
    "# add some inccorect ones to see how the judge LLM does\n",
    "df.loc['set-21'] = [positive_normal, 'negative']\n",
    "df.loc['set-22'] = [negative_normal, 'positive']\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "df['input'] =  SYSTEM_PROMPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evalute dataset for fine tuning\n",
    "\n",
    "throw some bad ones in there to ensure our eval is working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are given a question, an answer and reference text. You must determine whether the\n",
      "given answer correctly answers the question based on the reference text. Here is the data:\n",
      "    [BEGIN DATA]\n",
      "    ************\n",
      "    [Question]: {input}\n",
      "    ************\n",
      "    [Reference]: {reference}\n",
      "    ************\n",
      "    [Answer]: {output}\n",
      "    [END DATA]\n",
      "Your response must be a single word, either \"correct\" or \"incorrect\",\n",
      "and should not contain any text or characters aside from that word.\n",
      "\"correct\" means that the question is correctly and fully answered by the answer.\n",
      "\"incorrect\" means that the question is not correctly or only partially answered by the\n",
      "answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(templates.QA_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, the Judge LLM rightly identifies the incorrect training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIModel(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "rails = list(templates.QA_PROMPT_RAILS_MAP.values())\n",
    "Q_and_A_classifications = llm_classify(\n",
    "    dataframe=df,\n",
    "    template=templates.QA_PROMPT_TEMPLATE,\n",
    "    model=model,\n",
    "    rails=rails,\n",
    "    concurrency=10,\n",
    ")[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'incorrect',\n",
       " 'incorrect']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_and_A_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_df = pd.DataFrame.from_dict(parsed_response, orient='index', columns=['post', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetune_files(finetune_df):\n",
    "    '''create both training and validation jsonl files for fine-tuning the model'''\n",
    "    # Prepare to write to a .jsonl file\n",
    "    formatted_examples = []\n",
    "    for index, row in finetune_df.iterrows():\n",
    "        # Structure the data as needed for fine-tuning\n",
    "        formatted_example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": row.post},\n",
    "                {\"role\": \"assistant\", \"content\": row.sentiment}\n",
    "            ]\n",
    "        }\n",
    "        formatted_examples.append(formatted_example)\n",
    "    # split into train and validation sets\n",
    "    train = formatted_examples[:int(len(formatted_examples)*0.8)]\n",
    "    validation = formatted_examples[int(len(formatted_examples)*0.8):]    \n",
    "     # write each to a jsonl file\n",
    "    with open('fine_tune_train_data.jsonl', 'w') as file:\n",
    "        for example in train:\n",
    "            file.write(json.dumps(example) + '\\n')\n",
    "    \n",
    "    with open('fine_tune_validation_data.jsonl', 'w') as file:\n",
    "        for example in validation:\n",
    "            file.write(json.dumps(example) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_finetune_files(finetune_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file\n",
    "training_file_response = client.files.create(\n",
    "    file=open('fine_tune_train_data.jsonl', \"rb\"),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "training_file_id = training_file_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the validation file\n",
    "validation_file_response = client.files.create(\n",
    "    file=open('fine_tune_validation_data.jsonl', \"rb\"),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "validation_file_id = validation_file_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_info = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file_id, \n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  suffix=\"sentiment-classifier\",\n",
    "  validation_file=validation_file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = 'gpt-3.5-turbo-sentiment-classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(original_dataset, columns=['text', 'label'])\n",
    "df['predicted_label'] = df['text'].apply(classify_sentiment).apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
