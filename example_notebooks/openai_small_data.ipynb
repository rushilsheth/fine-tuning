{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this notebook we will follow the framework laid out by openai to finetune: [link](https://platform.openai.com/docs/guides/fine-tuning/introduction)\n",
    "\n",
    "we will syntheitcally create our dataset using an LLM by boostrapping a few samples. we will then evaulate the validity of this dataset using an LLM.\n",
    "\n",
    "will repurpose the Q&A on Retrieved Data in Arize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rushilsheth/Documents/portfolio/fine-tuning/example_notebooks/openai-small-example-venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from jinja2 import Template\n",
    "from sklearn.metrics import classification_report\n",
    "from pycm import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openai import OpenAI\n",
    "import phoenix.evals.default_templates as templates\n",
    "from phoenix.evals import (\n",
    "    OpenAIModel,\n",
    "    llm_classify,\n",
    ")\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets try to predict normally with 3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_normal = '''I recently purchased the Galaxy Explorer drone and am absolutely thrilled with its performance. The drone's battery life is impressive, allowing for extended flight times, and the camera quality is outstanding, capturing crisp and clear images from great heights. The intuitive controls made it easy for me as a beginner to navigate, and I've been able to capture some truly breathtaking footage. Highly recommend to anyone looking for a reliable and high-quality drone.'''\n",
    "negative_normal = '''Had dinner at The Green Terrace last night and was deeply disappointed. Despite the cozy ambiance, the service was sluggish, and our orders took forever to arrive. When the food finally came, it was lukewarm at best. The pasta was overcooked, and the salad lacked freshness. It's a shame because I had high expectations based on the reviews. Sadly, I won't be returning or recommending this place to friends.'''\n",
    "positive_tough = '''Lost my job, but at least I won't have to endure that dreadful commute anymore'''\n",
    "negative_tough = '''Your presentation was surprisingly good; I expected much less'''\n",
    "\n",
    "SYSTEM_PROMPT = '''You are given a social media review. Classify it as postive, negative. '''\n",
    "\n",
    "original_dataset = [[positive_normal, 'positive'],\n",
    "               [negative_normal, 'negative'], \n",
    "               [positive_tough, 'positive'],\n",
    "               [negative_tough, 'negative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(social_media_post, model=\"gpt-3.5-turbo\"):\n",
    "    response = client.chat.completions.create(model=model, \n",
    "                                              temperature = 0.1,\n",
    "                                              messages=[{\"role\": \"system\", \"content\": SYSTEM_PROMPT}, \n",
    "                                                        {\"role\": \"user\", \"content\": social_media_post}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(original_dataset, columns=['text', 'label'])\n",
    "df['predicted_label'] = df['text'].apply(classify_sentiment).apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct'] = df['label'] == df['predicted_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_incorrect = df[~df['correct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy for base gpt-3.5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I recently purchased the Galaxy Explorer drone...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Had dinner at The Green Terrace last night and...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lost my job, but at least I won't have to endu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your presentation was surprisingly good; I exp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  I recently purchased the Galaxy Explorer drone...  positive   \n",
       "1  Had dinner at The Green Terrace last night and...  negative   \n",
       "2  Lost my job, but at least I won't have to endu...  positive   \n",
       "3  Your presentation was surprisingly good; I exp...  negative   \n",
       "\n",
       "  predicted_label  correct  \n",
       "0        positive     True  \n",
       "1        negative     True  \n",
       "2        negative    False  \n",
       "3        positive    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correct'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a dataset for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are responsible for creating a dataset of social media posts and their associated sentiments(postiive or negative).\n",
      "\n",
      "Read the instructions below carefully and follow each step in order to accurately generate your response.\n",
      "\n",
      "Please generate 20 sets of social media posts. Each set should not share similar context.\n",
      "\n",
      "Please output the sets in the following format:\n",
      "{'set-1': [<POST>, sentiment],\n",
      "    'set-2': [<POST>, sentiment], ...,\n",
      "    'set-20': [<POST>, sentiment]}\n",
      "\n",
      "Here are some examples:\n",
      "{'set-1': (\"I recently purchased the Galaxy Explorer drone and am absolutely thrilled with its performance. The drone's battery life is impressive, allowing for extended flight times, and the camera quality is outstanding, capturing crisp and clear images from great heights. The intuitive controls made it easy for me as a beginner to navigate, and I've been able to capture some truly breathtaking footage. Highly recommend to anyone looking for a reliable and high-quality drone.\", 'positive'),\n",
      "    'set-2': (\"Had dinner at The Green Terrace last night and was deeply disappointed. Despite the cozy ambiance, the service was sluggish, and our orders took forever to arrive. When the food finally came, it was lukewarm at best. The pasta was overcooked, and the salad lacked freshness. It's a shame because I had high expectations based on the reviews. Sadly, I won't be returning or recommending this place to friends.\", 'negative'),\n",
      "    'set-3': (\"Lost my job, but at least I won't have to endure that dreadful commute anymore\", 'positive'),\n",
      "    'set-4': (\"Your presentation was surprisingly good; I expected much less\", 'negative')}\n",
      "\n",
      "1. Please provide your response in a strictly valid RFC8259 JSON format.\n",
      "2. Your JSON response should exclude any characters or text that are not part of the JSON structure, such as the word 'json', annotations, markdown syntax, or clarifying text.\n",
      "3. Begin your response with a JSON opening curly brace and end with a closing curly brace. The response should consist solely of the JSON object.\n",
      "4. Ensure your JSON response does not include whitespaces.\n",
      "\n",
      "No whitespace RFC8259-compliant JSON response (do not truncate):\n"
     ]
    }
   ],
   "source": [
    "# Format the examples\n",
    "formatted_examples = \",\\n    \".join([f\"'set-{i+1}': (\\\"{text}\\\", '{sentiment}')\" for i, (text, sentiment) in enumerate(original_dataset)])\n",
    "formatted_examples = '{'+formatted_examples+'}'\n",
    "\n",
    "# Step 1: Read the file content\n",
    "with open('dataset_generator_template.txt', 'r') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# Step 3: Render the template with examples\n",
    "template = Template(file_content)\n",
    "dataset_gen_system_prompt = template.render(examples=formatted_examples)\n",
    "\n",
    "print(dataset_gen_system_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_dataset():\n",
    "    dataset_response = client.chat.completions.create(model='gpt-4-turbo-preview', \n",
    "                                              temperature = 0.1,\n",
    "                                              messages=[{\"role\": \"system\", \"content\": dataset_gen_system_prompt}, \n",
    "                                                        {\"role\": \"user\", \"content\": \"JSON Response:\"}]).choices[0].message.content\n",
    "    # sometimes the string ```json``` is not present in the response, so we need to check for it\n",
    "    # if it is in there we want to remove it and the trailing ``` from the response\n",
    "    if 'json' in dataset_response:\n",
    "        parsed_response = dataset_response.replace('json', '')\n",
    "        parsed_response = parsed_response.replace('`', '')\n",
    "        parsed_response = json.loads(parsed_response)\n",
    "    else:\n",
    "        parsed_response = json.loads(dataset_response)\n",
    "    \n",
    "    return parsed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_response = generate_synthetic_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(parsed_response, orient='index', columns=['reference', 'output'])\n",
    "# add some inccorect ones to see how the judge LLM does\n",
    "df.loc['set-21'] = [positive_normal, 'negative']\n",
    "df.loc['set-22'] = [negative_normal, 'positive']\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "df['input'] =  SYSTEM_PROMPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evalute dataset for fine tuning\n",
    "\n",
    "throw some bad ones in there to ensure our eval is working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are given a question, an answer and reference text. You must determine whether the\n",
      "given answer correctly answers the question based on the reference text. Here is the data:\n",
      "    [BEGIN DATA]\n",
      "    ************\n",
      "    [Question]: {input}\n",
      "    ************\n",
      "    [Reference]: {reference}\n",
      "    ************\n",
      "    [Answer]: {output}\n",
      "    [END DATA]\n",
      "Your response must be a single word, either \"correct\" or \"incorrect\",\n",
      "and should not contain any text or characters aside from that word.\n",
      "\"correct\" means that the question is correctly and fully answered by the answer.\n",
      "\"incorrect\" means that the question is not correctly or only partially answered by the\n",
      "answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(templates.QA_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, the Judge LLM rightly identifies the incorrect training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |██████████| 22/22 (100.0%) | ⏳ 00:06<00:00 |  3.25it/s\n"
     ]
    }
   ],
   "source": [
    "model = OpenAIModel(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "rails = list(templates.QA_PROMPT_RAILS_MAP.values())\n",
    "Q_and_A_classifications = llm_classify(\n",
    "    dataframe=df,\n",
    "    template=templates.QA_PROMPT_TEMPLATE,\n",
    "    model=model,\n",
    "    rails=rails,\n",
    "    concurrency=10,\n",
    ")[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'correct',\n",
       " 'incorrect',\n",
       " 'incorrect']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_and_A_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_df = pd.DataFrame.from_dict(parsed_response, orient='index', columns=['post', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetune_files(finetune_df):\n",
    "    '''create both training and validation jsonl files for fine-tuning the model'''\n",
    "    # Prepare to write to a .jsonl file\n",
    "    formatted_examples = []\n",
    "    for index, row in finetune_df.iterrows():\n",
    "        # Structure the data as needed for fine-tuning\n",
    "        formatted_example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": row.post},\n",
    "                {\"role\": \"assistant\", \"content\": row.sentiment}\n",
    "            ]\n",
    "        }\n",
    "        formatted_examples.append(formatted_example)\n",
    "    # split into train and validation sets\n",
    "    train = formatted_examples[:int(len(formatted_examples)*0.8)]\n",
    "    validation = formatted_examples[int(len(formatted_examples)*0.8):]    \n",
    "     # write each to a jsonl file\n",
    "    with open('fine_tune_train_data.jsonl', 'w') as file:\n",
    "        for example in train:\n",
    "            file.write(json.dumps(example) + '\\n')\n",
    "    \n",
    "    with open('fine_tune_validation_data.jsonl', 'w') as file:\n",
    "        for example in validation:\n",
    "            file.write(json.dumps(example) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_finetune_files(finetune_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file\n",
    "training_file_response = client.files.create(\n",
    "    file=open('fine_tune_train_data.jsonl', \"rb\"),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "training_file_id = training_file_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the validation file\n",
    "validation_file_response = client.files.create(\n",
    "    file=open('fine_tune_validation_data.jsonl', \"rb\"),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "validation_file_id = validation_file_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_info = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file_id, \n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  suffix=\"sentiment-small\",\n",
    "  validation_file=validation_file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0125:personal:sentiment-small:8zh5RxzN\n",
      "ft:gpt-3.5-turbo-0613:personal:spam-classifier:8pLNGstw\n"
     ]
    }
   ],
   "source": [
    "for ft_job in client.fine_tuning.jobs.list(limit=5).data:\n",
    "    print(ft_job.fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = 'ft:gpt-3.5-turbo-0125:personal:sentiment-small:8zh5RxzN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(original_dataset, columns=['text', 'label'])\n",
    "new_df['predicted_label'] = new_df['text'].apply(lambda x: classify_sentiment(x, model=ft_model)).apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I recently purchased the Galaxy Explorer drone...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Had dinner at The Green Terrace last night and...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lost my job, but at least I won't have to endu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your presentation was surprisingly good; I exp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label predicted_label\n",
       "0  I recently purchased the Galaxy Explorer drone...  positive        positive\n",
       "1  Had dinner at The Green Terrace last night and...  negative        negative\n",
       "2  Lost my job, but at least I won't have to endu...  positive        positive\n",
       "3  Your presentation was surprisingly good; I exp...  negative        negative"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
